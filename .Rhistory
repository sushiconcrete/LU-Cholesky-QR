sum(b[2:54])
sum(b)
b[1]
sum(b[2:54]) + b[1]
sum(b[1:53])
u <- c(1, 2, 3, 3, 2, 1) # Define u as a vector.
# a) Compute U.
d <- as.vector(t(u) %*% u) # Convert d from matrix to vector and calculate d = t(u) * u.
U <- diag( length(u) ) - (2 / d) * u %*% t(u)
print(U)
sprintf("%a", 3)
1/0.0001
A <- matrix(c(7, 3, -1, 2, 3, 7, 8, 1, -4,
-1, 1, 4, -1, 2, -4, -1, 6), 4, 4)
luA <- lu(A)
elu <- expand(luA)
L <- elu$L
U <- elu$U
P <- elu$P
A <- matrix(c(7, 3, -1, 2, 3, 7, 8, 1, -4, -1, 1, 4, -1, 2, -4, -1, 6), 4, 4)
A <- matrix(c(7, 3, -1, 2, 3, 8, 1, -4, -1, 1, 4, -1, 2, -4, -1, 6), 4, 4)
luA <- lu(A)
elu <- expand(luA)
library(Matrix)
luA <- lu(A)
elu <- expand(luA)
L <- elu$L
U <- elu$U
P <- elu$P
P
U
help(lu)
# install.packages("Matrix")
library(Matrix)
luA <- lu(A)
elu <- expand(luA)
A <- matrix(c(7, 3, -1, 2, 3, 8, 1, -4, -1, 1, 4, -1, 2, -4, -1, 6), 4, 4)
# install.packages("Matrix")
library(Matrix)
luA <- lu(A)
elu <- expand(luA)
L <- elu$L
U <- elu$U
P <- elu$P
L
U
P
library(parallel)
detectCores()
library(parallel)
detectCores()
help(eigen)
help(svd)
setwd("~/Desktop/2022Winter-teaching/STA 141C/hws/hw2/")
tA <- read.table("ucd/A.txt", sep = ",")
tA <- as.matrix(tA)
A <- t(tA)
U <- read.table("ucd/U.txt", sep = " ")
U <- U$V1
dim(A)[1]
sum(A)
outdeg <- rowSums(A)
sum(outdeg < 1)
indeg <- colSums(A)
idxideg <- which.max(indeg)
U[idxideg]
indeg[idxideg]
idxodeg <- which.max(outdeg)
U[idxodeg]
outdeg[idxodeg]
image(1:dim(A)[1], 1:dim(A)[2], A, col = c("#FFFFFF", "#000000"),
xlab="", ylab="")
rmidx <- c(2, 46, 69, 150, 323, 382, 471)
U[rmidx]
Unew <- U[-rmidx]
Anew <- A[-rmidx, -rmidx]
# precompute some variables
# use sparse matrix to speed up computation
Asp <- Matrix(A, sparse = TRUE)
outdeg <- rowSums(Asp)
outdeginv <- ifelse(outdeg > 0, telep / outdeg, 0)
z <- ifelse(outdeg > 0, 1 - telep, 1) / n
# G is the R^+ A matrix
G <- outdeginv * Asp
P <- G + z
# eigen-decomposition
eig.tp <- eigen(t(P), symmetric = FALSE)
pgrank <- Re(eig.tp$vectors[, which.max(Re(eig.tp$values))])
# precompute some variables
# use sparse matrix to speed up computation
A <- Anew
Asp <- Matrix(A, sparse = TRUE)
outdeg <- rowSums(Asp)
# precompute some variables
# use sparse matrix to speed up computation
library("Matrix")
A <- Anew
Asp <- Matrix(A, sparse = TRUE)
outdeg <- rowSums(Asp)
outdeginv <- ifelse(outdeg > 0, telep / outdeg, 0)
z <- ifelse(outdeg > 0, 1 - telep, 1) / n
telep <- 0.85
A <- Anew
Asp <- Matrix(A, sparse = TRUE)
outdeg <- rowSums(Asp)
outdeginv <- ifelse(outdeg > 0, telep / outdeg, 0)
z <- ifelse(outdeg > 0, 1 - telep, 1) / n
n <- dim(A)[1]
A <- Anew
Asp <- Matrix(A, sparse = TRUE)
outdeg <- rowSums(Asp)
outdeginv <- ifelse(outdeg > 0, telep / outdeg, 0)
z <- ifelse(outdeg > 0, 1 - telep, 1) / n
# G is the R^+ A matrix
G <- outdeginv * Asp
P <- G + z
# eigen-decomposition
eig.tp <- eigen(t(P), symmetric = FALSE)
pgrank <- Re(eig.tp$vectors[, which.max(Re(eig.tp$values))])
eig.tp
eig.tp$values
Re(eig.tp$values)
# svd
svd.r <- svd(t(P))
svd.r$d
svd.r$u
help(Svd)
help(svd)
res <- eigen(t(P) %*% P)
res$values
res.svd <- svd(t(P) %*% P)
res.svd$d
help("svd,Matrix-method:")
help("svd,Matrix-method")
help(sv)
help("svd,Matrix-method")
help("svd")
svd.r$d
help(eigen)
res <- svd(t(P) %*% P)
res$d
res <- svd(t(P))
res$d
sqrt(res$d)
res <- svd(t(P) %*% P)
sqrt(res)
sqrt(res$d)
res$u[1:10,1:10]
res$v[1:10,1:10]
res <- svd(t(P))
res$v[1:10,1:10]
res$u[1:10,1:10]
t(res$u)[1:10,1:10]
svd.tp <- svd(t(P))
u <- svd.tp$u
u[1:20]
pgrank[1:20]
v <- svd.tp$v[1:20]
v
eig.tp$vectors[1:20]
timing.power <-
system.time(ucdstatpgrk.power <- pagerank(Anew, method = "power"))
timing.power
#' PageRank algorithm for computing ranks of pages based on connectivity matrix
#'
#' \code{pagerank} implements the PageRank algorithm using LU, Jacobi, Eigen,
#' and Power methods.
#'
#' @param A an n-by-by connectivity matrix with $a_{ij}=1$ if i links to j
#' @param telep the teleportation parameter with a default value of 0.85
#' @param method the numerical method for PageRank algorithm, default is "lu"
#' @param maxiter the maximum iterations for Jacobi and Power methods
#' @param tolx the tolerance in the l1 norm of solution
#' @param x0 starting point
#' @return the vector of page ranks (normalized to have sum 1)
#' @seealso
pagerank <- function(A, telep = 0.85, method = "lu", maxiter = 1000,
tolx = 1e-3, x0 = NULL) {
# check dimension
if (!is.matrix(A) || dim(A)[1] != dim(A)[2])
stop("A must be a square matrix")
n <- dim(A)[1] # n = number of pages
if (!is.null(x0) && length(x0) != n)
stop("starting vector x0 should have same length as dim(A)[1]")
# load the Matrix package if not yet
if (!is.element("Matrix", installed.packages()[, 1])) {
install.packages(Matrix, repos = "http://cran.us.r-project.org")
library(Matrix)
}
# precompute some variables
# use sparse matrix to speed up computation
Asp <- Matrix(A, sparse = TRUE)
outdeg <- rowSums(Asp)
outdeginv <- ifelse(outdeg > 0, telep / outdeg, 0)
z <- ifelse(outdeg > 0, 1 - telep, 1) / n
# G is the R^+ A matrix
G <- outdeginv * Asp
# compute page ranks
if (method == "lu") {
# prepare the linear system I - P^t
M <- - t(G + z)
diag(M) <- diag(M) + 1
# replace the first equation by the sum-to-1 constraint
M[1, ] <- 1
# LU solve with right hand side e_1
pgrank <- solve(M, c(1, rep(0, n - 1)))
} else if (method == "qr") {
# prepare the linear system M = I - P
M <- - (G + z)
diag(M) <- diag(M) + 1
# QR decomposition (with column pivoting) of M
# last column of Q is in N(I-P^T), which is retrieved by Q e_n
pgrank <- qr.qy(qr(M), c(rep(0, n - 1), 1))
pgrank <- abs(pgrank / sum(pgrank))
} else if (method == "jacobi") {
# set starting point
if (is.null(x0)) {
x = rep(1 / n, n)
} else {
x = abs(x0 / sum(x0))
}
# obtain diagonal of the linear system
dg <- 1 - diag(G) - z
# Jacobi iterations
for (iter in 1:maxiter) {
xold <- x
# this is (I - P^T)x
x <- x - x %*% G - sum(x * z)
# this is Jacobi update
x <- xold - x / dg
# re-normalize: not necessary
# x <- x / sum(x)
# stopping criterion: change in L1 norm
if (sum(abs(x - xold)) < tolx)
break
}
if (iter == maxiter) {
warning(paste("fail to converge in", maxiter, " iterations!"))
} else {
print(paste("converged in", iter, "iterations"))
}
pgrank <- abs(x / sum(x))
} else if (method == "eig") {
# prepare the transition matrix
P <- G + z
# eigen-decomposition
eig.tp <- eigen(t(P), symmetric = FALSE)
pgrank <- Re(eig.tp$vectors[, which.max(Re(eig.tp$values))])
# normalize
pgrank <- abs(pgrank / sum(pgrank))
} else if (method == "power") {
# set starting point
if (is.null(x0)) {
x = rep(1 / n, n)
} else {
x = abs(x0 / sum(x0))
}
# Power iterations
for (iter in 1:maxiter) {
xold <- x
# this is Power update
x <- x %*% G + sum(x * z)
# re-normalize
x <- x / sqrt(sum(x^2))
# stopping criterion: change in L1 norm
if (sum(abs(x - xold)) < tolx)
break
}
if (iter == maxiter) {
warning(paste("fail to converge in", maxiter, " iterations!"))
} else {
print(paste("converged in", iter, "iterations"))
}
# normalize
pgrank <- x / sum(x)
} else {
stop("unknown method option")
}
# output
return(pgrank)
}
timing.power <-
system.time(ucdstatpgrk.power <- pagerank(Anew, method = "power"))
timing.power
topidx.j <- order(ucdstatpgrk.power, decreasing = TRUE)[1:20]
toplist.j <- cbind(Unew[topidx.j], ucdstatpgrk.power[topidx.j],
indeg[topidx.j], outdeg[topidx.j])
colnames(toplist.j) <- c("url", "page rank", "in-deg", "out-deg")
kable(toplist.j, format = "pandoc", caption = "PageRank by Jacobi",
align = c("l", "l", "l", "l"), row.names = FALSE)
setwd("~/Desktop/2022Winter-teaching/STA 141C/hws/hw2/")
tA <- read.table("ucd/A.txt", sep = ",")
tA <- as.matrix(tA)
A <- t(tA)
U <- read.table("ucd/U.txt", sep = " ")
U <- U$V1
dim(A)[1]
sum(A)
outdeg <- rowSums(A)
sum(outdeg < 1)
indeg <- colSums(A)
idxideg <- which.max(indeg)
U[idxideg]
indeg[idxideg]
idxodeg <- which.max(outdeg)
U[idxodeg]
outdeg[idxodeg]
image(1:dim(A)[1], 1:dim(A)[2], A, col = c("#FFFFFF", "#000000"),
xlab="", ylab="")
rmidx <- c(2, 46, 69, 150, 323, 382, 471)
U[rmidx]
Unew <- U[-rmidx]
Anew <- A[-rmidx, -rmidx]
# precompute some variables
# use sparse matrix to speed up computation
library("Matrix")
telep <- 0.85
n <- dim(A)[1]
#' and Power methods.
#'
#' @param A an n-by-by connectivity matrix with $a_{ij}=1$ if i links to j
#' @param telep the teleportation parameter with a default value of 0.85
#' @param method the numerical method for PageRank algorithm, default is "lu"
#' @param maxiter the maximum iterations for Jacobi and Power methods
#' @param tolx the tolerance in the l1 norm of solution
#' @param x0 starting point
#' @return the vector of page ranks (normalized to have sum 1)
#' @seealso
pagerank <- function(A, telep = 0.85, method = "lu", maxiter = 1000,
tolx = 1e-3, x0 = NULL) {
# check dimension
if (!is.matrix(A) || dim(A)[1] != dim(A)[2])
stop("A must be a square matrix")
n <- dim(A)[1] # n = number of pages
if (!is.null(x0) && length(x0) != n)
stop("starting vector x0 should have same length as dim(A)[1]")
# load the Matrix package if not yet
if (!is.element("Matrix", installed.packages()[, 1])) {
install.packages(Matrix, repos = "http://cran.us.r-project.org")
library(Matrix)
}
# precompute some variables
# use sparse matrix to speed up computation
Asp <- Matrix(A, sparse = TRUE)
outdeg <- rowSums(Asp)
outdeginv <- ifelse(outdeg > 0, telep / outdeg, 0)
z <- ifelse(outdeg > 0, 1 - telep, 1) / n
# G is the R^+ A matrix
G <- outdeginv * Asp
# compute page ranks
if (method == "lu") {
# prepare the linear system I - P^t
M <- - t(G + z)
diag(M) <- diag(M) + 1
# replace the first equation by the sum-to-1 constraint
M[1, ] <- 1
# LU solve with right hand side e_1
pgrank <- solve(M, c(1, rep(0, n - 1)))
} else if (method == "qr") {
# prepare the linear system M = I - P
M <- - (G + z)
diag(M) <- diag(M) + 1
# QR decomposition (with column pivoting) of M
# last column of Q is in N(I-P^T), which is retrieved by Q e_n
pgrank <- qr.qy(qr(M), c(rep(0, n - 1), 1))
pgrank <- abs(pgrank / sum(pgrank))
} else if (method == "jacobi") {
# set starting point
if (is.null(x0)) {
x = rep(1 / n, n)
} else {
x = abs(x0 / sum(x0))
}
# obtain diagonal of the linear system
dg <- 1 - diag(G) - z
# Jacobi iterations
for (iter in 1:maxiter) {
xold <- x
# this is (I - P^T)x
x <- x - x %*% G - sum(x * z)
# this is Jacobi update
x <- xold - x / dg
# re-normalize: not necessary
# x <- x / sum(x)
# stopping criterion: change in L1 norm
if (sum(abs(x - xold)) < tolx)
break
}
if (iter == maxiter) {
warning(paste("fail to converge in", maxiter, " iterations!"))
} else {
print(paste("converged in", iter, "iterations"))
}
pgrank <- abs(x / sum(x))
} else if (method == "eig") {
# prepare the transition matrix
P <- G + z
# eigen-decomposition
eig.tp <- eigen(t(P), symmetric = FALSE)
pgrank <- Re(eig.tp$vectors[, which.max(Re(eig.tp$values))])
# normalize
pgrank <- abs(pgrank / sum(pgrank))
} else if (method == "power") {
# set starting point
if (is.null(x0)) {
x = rep(1 / n, n)
} else {
x = abs(x0 / sum(x0))
}
# Power iterations
for (iter in 1:maxiter) {
xold <- x
# this is Power update
x <- x %*% G + sum(x * z)
# re-normalize
x <- x / sqrt(sum(x^2))
# stopping criterion: change in L1 norm
if (sum(abs(x - xold)) < tolx)
break
}
if (iter == maxiter) {
warning(paste("fail to converge in", maxiter, " iterations!"))
} else {
print(paste("converged in", iter, "iterations"))
}
# normalize
pgrank <- x / sum(x)
} else {
stop("unknown method option")
}
# output
return(pgrank)
}
library(Matrix)
library(knitr)
timing.power <-
system.time(ucdstatpgrk.power <- pagerank(Anew, method = "power"))
timing.power
topidx.j <- order(ucdstatpgrk.power, decreasing = TRUE)[1:20]
toplist.j <- cbind(Unew[topidx.j], ucdstatpgrk.power[topidx.j],
indeg[topidx.j], outdeg[topidx.j])
colnames(toplist.j) <- c("url", "page rank", "in-deg", "out-deg")
kable(toplist.j, format = "pandoc", caption = "PageRank by Jacobi",
align = c("l", "l", "l", "l"), row.names = FALSE)
data(longley)
y <- as.matrix(longley$Employed)
df <- longley[, -which(names(longley) == "Employed")]
X <- as.matrix(cbind(1, df))  # Add intercept (ones) as the first column
X
start_time <- Sys.time()
beta_hat <- solve(t(X) %*% X) %*% t(X) %*% y  # Compute beta_hat
residuals <- y - X %*% beta_hat
n <- nrow(X)
p <- ncol(X)
sigma_hat_sq <- t(residuals) %*% residuals / (n - p)  # Compute sigma_hat_sq
var_beta_hat <- as.numeric(sigma_hat_sq) * solve(t(X) %*% X)  # Compute variance of beta_hat
se_beta_hat <- sqrt(diag(var_beta_hat))  # Compute SE of beta_hat
end_time <- Sys.time()
time_GE_LU <- end_time - start_time
time_GE_LU
start_time <- Sys.time()
XtX <- t(X) %*% X
XtX_inv <- chol2inv(chol(XtX))
beta_hat_chol <- XtX_inv %*% t(X) %*% y
residuals_chol <- y - X %*% beta_hat_chol
sigma_hat_sq_chol <- t(residuals_chol) %*% residuals_chol / (n - p)
var_beta_hat_chol <- as.numeric(sigma_hat_sq_chol) * XtX_inv
se_beta_hat_chol <- sqrt(diag(var_beta_hat_chol))
end_time <- Sys.time()
time_Cholesky <- end_time - start_time
time_Cholesky
start_time <- Sys.time()
qr_decomp <- qr(X)  # QR decomposition of X
R_inv <- solve(qr.R(qr_decomp))  # Inverse of R
Q <- qr.Q(qr_decomp)  # Q matrix
beta_hat_qr <- R_inv %*% t(Q) %*% y  # Compute beta_hat
residuals_qr <- y - X %*% beta_hat_qr
sigma_hat_sq_qr <- t(residuals_qr) %*% residuals_qr / (n - p)  # Compute sigma_hat_sq
var_beta_hat_qr <- as.numeric(sigma_hat_sq_qr) * R_inv %*% t(R_inv)  # Compute variance of beta_hat
se_beta_hat_qr <- sqrt(diag(var_beta_hat_qr))  # Compute SE of beta_hat
end_time <- Sys.time()
time_QR <- end_time - start_time
time_QR
model <- lm(Employed ~ ., data = longley)
summary(model)
beta_hat
beta_hat_chol
beta_hat_qr
lambda_values <- seq(0, 100, by = 50)
norms <- numeric(length(lambda_values))
for (i in seq_along(lambda_values)) {
lambda <- lambda_values[i]
beta_hat_ridge <- solve(t(X) %*% X + lambda * diag(p), t(X) %*% y)
norms[i] <- sqrt(sum(beta_hat_ridge^2))
}
plot(lambda_values, norms, type = "l", xlab = "Lambda", ylab = "L2-Norm of Ridge Coefficients", ylim = c(0,8000))
# load the parallel package
library(parallel)
lambda_values <- seq(0, 100, by = 50)
p <- ncol(X)
# create a function to calculate beta_hat_ridge and its norm
calc_norm <- function(lambda) {
beta_hat_ridge <- solve(t(X) %*% X + lambda * diag(p), t(X) %*% y)
norm <- sqrt(sum(beta_hat_ridge^2))
return(norm)
}
# use mclapply to calculate norms in parallel
norms <- mclapply(lambda_values, calc_norm, mc.cores = detectCores())
# since mclapply returns a list, unlist norms to a numeric vector
norms <- unlist(norms)
# plot the results
plot(lambda_values, norms, type = "l", xlab = "Lambda", ylab = "L2-Norm of Ridge Coefficients", ylim = c(0,8000))
